{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COSINE\n",
    "## Our method / Tensor Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "n_samples = 10000\n",
    "lower_bound = -2 * np.pi\n",
    "upper_bound = 2 * np.pi\n",
    "# lower_bound = -10\n",
    "# upper_bound = 10\n",
    "\n",
    "X = np.random.uniform(lower_bound, upper_bound, size=(n_samples, 1))\n",
    "#X = np.arange(lower_bound, upper_bound, 0.001)\n",
    "y = np.cos(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "def build_model(input_shape, filters):\n",
    "    rank = 3\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = input_layer\n",
    "\n",
    "    h1 = H1Layer()\n",
    "    h2 = H2Layer(h1)\n",
    "    h3 = H3Layer(h1,h2)\n",
    "    h4 = H4Layer(h2,h3)\n",
    "    x = Dense(filters)(x)\n",
    "    x = h2(x)\n",
    "    x = Dense(filters)(x)\n",
    "    x = TensorDecompositionLayer(rank)(x)\n",
    "    x = h3(x)\n",
    "    x = Dense(filters)(x)\n",
    "    x = TensorDecompositionLayer(rank)(x)\n",
    "    x = h4(x)\n",
    "    x = Dense(filters)(x)\n",
    "    x = TensorDecompositionLayer(rank)(x)\n",
    "    \n",
    "    output_layer = Dense(1)(x)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    return model \n",
    "\n",
    "\n",
    "input_shape = (1,)\n",
    "filters = 64\n",
    "modelN4 = build_model(input_shape, filters)\n",
    "modelN4.summary()\n",
    "optimizer = Adam(learning_rate=0.001) # Reduce learning rate\n",
    "modelN4.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 150\n",
    "\n",
    "history = modelN4.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[callback])\n",
    "\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "val_loss = modelN4.evaluate(X_val, y_val, verbose=0)\n",
    "print(f\"Validation loss: {val_loss}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_test_samples = 1000\n",
    "X_test = np.linspace(lower_bound, upper_bound, num=num_test_samples).reshape(-1, 1)\n",
    "y_true = np.cos(X_test)\n",
    "y_pred = modelN4.predict(X_test)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(X_test, y_true, label='True Cosine Values', color='b', linewidth=2)\n",
    "plt.plot(X_test, y_pred, label='Model Predictions', color='r', linestyle='--', linewidth=2)\n",
    "plt.xlabel('Input Value')\n",
    "plt.ylabel('Cosine Value')\n",
    "plt.title('Cosine Function and Model Predictions')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Number of epochs actually trained\n",
    "actual_epochs = len(history.history['loss'])\n",
    "\n",
    "# Plot the loss graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, actual_epochs + 1), train_loss[:actual_epochs], label='Training Loss', color='b', linewidth=2)\n",
    "plt.plot(range(1, actual_epochs + 1), history.history['val_loss'], label='Validation Loss', color='r', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Time')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# f(x1,x2)=3cos(2pi( x1^2-x2^2)) Prediction\n",
    "## Our method / CP decomposition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the function\n",
    "def f(x1, x2):\n",
    "    return 3 * np.cos(2 * np.pi * (x1**2 - x2**2))\n",
    "\n",
    "# Set the parameters\n",
    "lower_bound = -1\n",
    "upper_bound = 1\n",
    "n_samples = 1000\n",
    "\n",
    "# Generate the data\n",
    "x1_values = np.linspace(lower_bound, upper_bound, n_samples).reshape(n_samples, 1)\n",
    "x2_values = np.linspace(lower_bound, upper_bound, n_samples).reshape(n_samples, 1)\n",
    "\n",
    "# Get a meshgrid for x1 and x2 values\n",
    "X1, X2 = np.meshgrid(x1_values, x2_values)\n",
    "\n",
    "# Calculate y values using the function\n",
    "y_values = f(X1, X2)\n",
    "\n",
    "# Reshape the data for training\n",
    "X = np.column_stack((X1.ravel(), X2.ravel()))\n",
    "y = y_values.ravel()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Assuming H1Layer, H2Layer, H3Layer, H4Layer, H5Layer, and TensorDecompositionLayer are pre-defined\n",
    "def build_model(input_shape, filters):\n",
    "    rank = 4\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = input_layer\n",
    "\n",
    "    h1 = H1Layer()\n",
    "    h2 = H2Layer(h1)\n",
    "    h3 = H3Layer(h1,h2)\n",
    "    h4 = H4Layer(h2,h3)\n",
    "    h5 = H5Layer(h3,h4)\n",
    "\n",
    "    # Using 'he_normal' initialization for the Dense layers\n",
    "    x = Dense(filters, kernel_initializer='he_normal')(x)\n",
    "    x = h2(x)\n",
    "    x = Dense(filters, kernel_initializer='he_normal')(x)\n",
    "    x = TensorDecompositionLayer(rank)(x)\n",
    "    x = h3(x)\n",
    "    x = Dense(filters, kernel_initializer='he_normal')(x)\n",
    "    x = TensorDecompositionLayer(rank)(x)\n",
    "    x = h4(x)\n",
    "    x = Dense(filters, kernel_initializer='he_normal')(x)\n",
    "    x = TensorDecompositionLayer(rank)(x)\n",
    "    x = h5(x)\n",
    "    x = Dense(filters, kernel_initializer='he_normal')(x)\n",
    "    x = TensorDecompositionLayer(rank)(x)\n",
    "    \n",
    "    output_layer = Dense(1, )(x)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    return model \n",
    "\n",
    "\n",
    "input_shape = (2,)\n",
    "filters = 128\n",
    "modelN4 = build_model(input_shape, filters)\n",
    "optimizer = Adam(learning_rate=0.0001) # Reduce learning rate\n",
    "modelN4.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 20\n",
    "\n",
    "history = modelN4.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[callback])\n",
    "\n",
    "val_loss = modelN4.evaluate(X_val, y_val, verbose=0)\n",
    "print(f\"Validation loss: {val_loss}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "modelN4.summary()\n",
    "\n",
    "# 1. Extract loss values\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# 2. Determine the number of epochs\n",
    "actual_epochs = len(train_loss)\n",
    "\n",
    "# 3. Create a plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, actual_epochs + 1), train_loss, label='Training Loss', color='b', linewidth=2)\n",
    "plt.plot(range(1, actual_epochs + 1), val_loss, label='Validation Loss', color='r', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Time')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function f(x1,x2) = 3*sin*(pi*x1)* cos*(pi*x2)*cos*(pi^2*x1*x2)\n",
    "\n",
    "# THIS IS THE NEW 2 BRANCH ARCHITECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the function\n",
    "def f(x1, x2):\n",
    "    return 3 * np.sin(np.pi*x1)*np.cos(np.pi*x2)*np.cos(np.pi**2 *x1*x2)\n",
    "\n",
    "# Set the parameters\n",
    "lower_bound = -1\n",
    "upper_bound = 1\n",
    "n_samples = 1000\n",
    "\n",
    "# Generate the data\n",
    "x1_values = np.linspace(lower_bound, upper_bound, n_samples).reshape(n_samples, 1)\n",
    "x2_values = np.linspace(lower_bound, upper_bound, n_samples).reshape(n_samples, 1)\n",
    "\n",
    "# Get a meshgrid for x1 and x2 values\n",
    "X1, X2 = np.meshgrid(x1_values, x2_values)\n",
    "\n",
    "# Calculate y values using the function\n",
    "y_values = f(X1, X2)\n",
    "\n",
    "# # Reshape the data for training\n",
    "# X = np.column_stack((X1.ravel(), X2.ravel()))\n",
    "# y = y_values.ravel()\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Flatten the data for training\n",
    "X1_flat = X1.ravel().reshape(-1, 1)  # Reshaped as a 2D array for model input\n",
    "X2_flat = X2.ravel().reshape(-1, 1)  # Reshaped as a 2D array for model input\n",
    "y_flat = y_values.ravel()\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X1_train, X1_val, X2_train, X2_val, y_train, y_val = train_test_split(X1_flat, X2_flat, y_flat, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Assuming H1Layer, H2Layer, H3Layer, H4Layer, H5Layer, and TensorDecompositionLayer are pre-defined\n",
    "def build_model(input_shape, filters):\n",
    "\n",
    "    rank = 4\n",
    "    input_x1 = Input(shape=(1,))\n",
    "    input_x2 = Input(shape=(1,))\n",
    "\n",
    "    h1 = H1Layer()\n",
    "    h2 = H2Layer(h1)\n",
    "    h3 = H3Layer(h1,h2)\n",
    "    h4 = H4Layer(h2,h3)\n",
    "    h5 = H5Layer(h3,h4)\n",
    "    #Branch 1\n",
    "    branch_x1 = Dense(filters)(input_x1)\n",
    "    branch_x1 = Dense(filters)(branch_x1)\n",
    "\n",
    "    #Branch 2\n",
    "    branch_x2 = Dense(filters)(input_x2)\n",
    "    branch_x2 = Dense(filters)(branch_x2)\n",
    "\n",
    "    #Merge\n",
    "    merged = concatenate([branch_x1, branch_x2])\n",
    "    merged = Dense(filters)(merged)\n",
    "    merged = h2(merged)\n",
    "    merged = Dense(filters)(merged)\n",
    "    merged = TensorDecompositionLayer(rank)(merged)\n",
    "    merged = h3(merged)\n",
    "    merged = Dense(filters)(merged)\n",
    "    merged = TensorDecompositionLayer(rank)(merged)\n",
    "    merged = h4(merged)\n",
    "    merged = Dense(filters)(merged)\n",
    "    merged = TensorDecompositionLayer(rank)(merged)\n",
    "\n",
    "    output = Dense(1)(merged)  # Single output for your function\n",
    "    model = Model(inputs=[input_x1, input_x2], outputs=output)\n",
    "\n",
    "    return model \n",
    "\n",
    "\n",
    "input_shape = (2,)\n",
    "filters = 128\n",
    "modelN4 = build_model(input_shape, filters)\n",
    "optimizer = Adam(learning_rate=0.0001) # Reduce learning rate\n",
    "modelN4.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 20\n",
    "\n",
    "# history = modelN4.fit([X1_train], y_train,\n",
    "#                     batch_size=batch_size,\n",
    "#                     epochs=epochs,\n",
    "#                     verbose=1,\n",
    "#                     validation_data=(X_val, y_val),\n",
    "#                     callbacks=[callback])\n",
    "\n",
    "history = modelN4.fit([X1_train, X2_train], y_train,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs,\n",
    "                      verbose=1,\n",
    "                      validation_data=([X1_val, X2_val], y_val),\n",
    "                      callbacks=[callback])\n",
    "\n",
    "\n",
    "val_loss = modelN4.evaluate([X1_val, X2_val], y_val, verbose=0)\n",
    "print(f\"Validation loss: {val_loss}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "modelN4.summary()\n",
    "\n",
    "# 1. Extract loss values\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# 2. Determine the number of epochs\n",
    "actual_epochs = len(train_loss)\n",
    "\n",
    "# 3. Create a plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, actual_epochs + 1), train_loss, label='Training Loss', color='b', linewidth=2)\n",
    "plt.plot(range(1, actual_epochs + 1), val_loss, label='Validation Loss', color='r', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Time')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
