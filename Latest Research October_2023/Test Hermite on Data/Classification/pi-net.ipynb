{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-28 16:27:32.962306: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-28 16:27:33.473102: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.5) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "2023-09-28 16:27:34.537878: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-28 16:27:34.556290: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-28 16:27:34.556476: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-28 16:27:34.558563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-28 16:27:34.558702: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-28 16:27:34.558822: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-28 16:27:34.975712: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-28 16:27:34.975884: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-28 16:27:34.976009: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-28 16:27:34.976110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46210 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:4d:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Layer, Flatten, BatchNormalization, Conv2D,MaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# Path dataset\n",
    "test_folder = \"test\"\n",
    "train_folder = \"train\"\n",
    "valid_folder = \"valid\"\n",
    "\n",
    "# Result path\n",
    "result_path = f\"run\"\n",
    "os.makedirs(result_path, exist_ok=True)\n",
    "\n",
    "checkpoint_path = os.path.join(result_path, \"best_model.h5\")\n",
    "loss_image_path = os.path.join(result_path, 'validation loss.png')\n",
    "acc_image_path = os.path.join(result_path, 'validation accuracy.png')\n",
    "\n",
    "#### Hyperparameter\n",
    "image_size = (224, 224)\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "learning_rate = 0.0001\n",
    "\n",
    "#https://www.kaggle.com/datasets/gpiosenka/sports-classification/code\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('sports.csv')\n",
    "\n",
    "# Filter based on the data set column\n",
    "train_df = df[df['data set'] == 'train']\n",
    "valid_df = df[df['data set'] == 'valid']\n",
    "test_df = df[df['data set'] == 'test']\n",
    "\n",
    "# Extract filepaths and labels\n",
    "X_train_paths = train_df['filepaths'].values\n",
    "y_train_labels = train_df['class id'].values\n",
    "X_val_paths = valid_df['filepaths'].values\n",
    "y_val_labels = valid_df['class id'].values\n",
    "X_test_paths = test_df['filepaths'].values\n",
    "y_test_labels = test_df['class id'].values\n",
    "\n",
    "# Assuming y_train_labels and y_val_labels are your labels and num_classes is the number of classes.\n",
    "y_train = to_categorical(y_train_labels, num_classes=100)\n",
    "y_val = to_categorical(y_val_labels, num_classes=100)\n",
    "y_test = to_categorical(y_test_labels, num_classes=100)\n",
    "\n",
    "# Function to load and preprocess each image\n",
    "def load_and_preprocess_image(filepath, label):\n",
    "    img = tf.io.read_file(filepath)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, [224, 224])\n",
    "    img /= 255.0  # normalize to [0,1] range\n",
    "    return img, label\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_paths, y_train))\n",
    "train_dataset = train_dataset.map(load_and_preprocess_image)\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val_paths, y_val))\n",
    "val_dataset = val_dataset.map(load_and_preprocess_image)\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test_paths, y_test))\n",
    "test_dataset = test_dataset.map(load_and_preprocess_image)\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "422/422 [==============================] - 45s 86ms/step - loss: 8.5197 - accuracy: 0.0071 - val_loss: 8.4262 - val_accuracy: 0.0100\n",
      "Epoch 2/50\n",
      "422/422 [==============================] - 35s 83ms/step - loss: 9.0625 - accuracy: 0.0059 - val_loss: 8.1617 - val_accuracy: 0.0100\n",
      "Epoch 3/50\n",
      "422/422 [==============================] - 35s 83ms/step - loss: 8.5251 - accuracy: 0.0090 - val_loss: 8.7572 - val_accuracy: 0.0020\n",
      "Epoch 4/50\n",
      "422/422 [==============================] - 35s 83ms/step - loss: 8.6626 - accuracy: 0.0050 - val_loss: 7.9653 - val_accuracy: 0.0120\n",
      "Epoch 5/50\n",
      "422/422 [==============================] - 35s 84ms/step - loss: 8.7262 - accuracy: 0.0082 - val_loss: 9.0227 - val_accuracy: 0.0080\n",
      "Epoch 6/50\n",
      "422/422 [==============================] - 36s 84ms/step - loss: 7.8187 - accuracy: 0.0096 - val_loss: 8.0366 - val_accuracy: 0.0040\n",
      "Epoch 7/50\n",
      "422/422 [==============================] - 36s 84ms/step - loss: 8.6551 - accuracy: 0.0072 - val_loss: 8.6081 - val_accuracy: 0.0120\n",
      "Epoch 8/50\n",
      "422/422 [==============================] - 36s 85ms/step - loss: 8.1912 - accuracy: 0.0087 - val_loss: 8.8162 - val_accuracy: 0.0080\n",
      "Epoch 9/50\n",
      "422/422 [==============================] - 36s 85ms/step - loss: 8.2605 - accuracy: 0.0086 - val_loss: 8.7626 - val_accuracy: 0.0060\n",
      "Epoch 10/50\n",
      "422/422 [==============================] - 36s 85ms/step - loss: 6.8504 - accuracy: 0.0083 - val_loss: 8.7359 - val_accuracy: 0.0060\n",
      "Epoch 11/50\n",
      "422/422 [==============================] - 36s 85ms/step - loss: 7.2962 - accuracy: 0.0092 - val_loss: 9.3121 - val_accuracy: 0.0040\n",
      "Epoch 12/50\n",
      "422/422 [==============================] - 36s 85ms/step - loss: 7.2317 - accuracy: 0.0067 - val_loss: 8.1755 - val_accuracy: 0.0040\n",
      "Epoch 13/50\n",
      "422/422 [==============================] - 36s 85ms/step - loss: 8.5208 - accuracy: 0.0065 - val_loss: 9.2219 - val_accuracy: 0.0020\n",
      "Epoch 14/50\n",
      "422/422 [==============================] - 36s 85ms/step - loss: 8.9742 - accuracy: 0.0055 - val_loss: 8.7375 - val_accuracy: 0.0040\n",
      "Epoch 15/50\n",
      "422/422 [==============================] - 36s 85ms/step - loss: 8.5383 - accuracy: 0.0079 - val_loss: 8.4896 - val_accuracy: 0.0060\n",
      "Epoch 16/50\n",
      "422/422 [==============================] - 36s 85ms/step - loss: 8.2696 - accuracy: 0.0090 - val_loss: 8.1713 - val_accuracy: 0.0120\n",
      "Epoch 17/50\n",
      "422/422 [==============================] - 36s 85ms/step - loss: 8.1155 - accuracy: 0.0106 - val_loss: 8.0658 - val_accuracy: 0.0080\n",
      "Epoch 18/50\n",
      "422/422 [==============================] - 36s 85ms/step - loss: 8.2213 - accuracy: 0.0093 - val_loss: 7.9943 - val_accuracy: 0.0120\n",
      "Epoch 19/50\n",
      "422/422 [==============================] - 35s 84ms/step - loss: 9.3871 - accuracy: 0.0121 - val_loss: 8.0252 - val_accuracy: 0.0080\n",
      "Epoch 20/50\n",
      "422/422 [==============================] - 35s 84ms/step - loss: 7.6806 - accuracy: 0.0071 - val_loss: 8.4339 - val_accuracy: 0.0180\n",
      "Epoch 21/50\n",
      "422/422 [==============================] - 35s 84ms/step - loss: 7.8389 - accuracy: 0.0086 - val_loss: 8.2666 - val_accuracy: 0.0140\n",
      "Epoch 22/50\n",
      "422/422 [==============================] - 35s 83ms/step - loss: 8.0748 - accuracy: 0.0080 - val_loss: 8.6567 - val_accuracy: 0.0120\n",
      "Epoch 23/50\n",
      "422/422 [==============================] - 36s 85ms/step - loss: 8.3471 - accuracy: 0.0093 - val_loss: 8.3838 - val_accuracy: 0.0160\n",
      "Epoch 24/50\n",
      "422/422 [==============================] - 36s 85ms/step - loss: 7.0755 - accuracy: 0.0087 - val_loss: 7.9787 - val_accuracy: 0.0160\n",
      "Epoch 25/50\n",
      "422/422 [==============================] - 36s 85ms/step - loss: 7.6447 - accuracy: 0.0101 - val_loss: 7.4491 - val_accuracy: 0.0120\n",
      "Epoch 26/50\n",
      "422/422 [==============================] - 36s 85ms/step - loss: 6.8924 - accuracy: 0.0104 - val_loss: 8.0455 - val_accuracy: 0.0140\n",
      "Epoch 27/50\n",
      "422/422 [==============================] - 36s 84ms/step - loss: 7.2366 - accuracy: 0.0098 - val_loss: 8.4095 - val_accuracy: 0.0080\n",
      "Epoch 28/50\n",
      "422/422 [==============================] - 36s 85ms/step - loss: 7.5432 - accuracy: 0.0105 - val_loss: 7.6113 - val_accuracy: 0.0080\n",
      "Epoch 29/50\n",
      "422/422 [==============================] - 36s 84ms/step - loss: 7.9081 - accuracy: 0.0102 - val_loss: 8.3153 - val_accuracy: 0.0100\n",
      "Epoch 30/50\n",
      "422/422 [==============================] - 35s 84ms/step - loss: 8.2972 - accuracy: 0.0104 - val_loss: 8.0649 - val_accuracy: 0.0060\n",
      "Epoch 31/50\n",
      "422/422 [==============================] - 35s 84ms/step - loss: 7.6051 - accuracy: 0.0099 - val_loss: 8.3611 - val_accuracy: 0.0080\n",
      "Epoch 32/50\n",
      "422/422 [==============================] - 35s 83ms/step - loss: 7.5534 - accuracy: 0.0089 - val_loss: 8.5923 - val_accuracy: 0.0060\n",
      "Epoch 33/50\n",
      "422/422 [==============================] - 35s 83ms/step - loss: 7.4816 - accuracy: 0.0100 - val_loss: 8.0517 - val_accuracy: 0.0080\n",
      "Epoch 34/50\n",
      "422/422 [==============================] - 32s 77ms/step - loss: 8.4334 - accuracy: 0.0108 - val_loss: 7.7836 - val_accuracy: 0.0080\n",
      "Epoch 35/50\n",
      "422/422 [==============================] - 33s 77ms/step - loss: 7.4657 - accuracy: 0.0096 - val_loss: 8.1124 - val_accuracy: 0.0060\n",
      "Epoch 36/50\n",
      "422/422 [==============================] - 33s 78ms/step - loss: 8.2738 - accuracy: 0.0095 - val_loss: 8.1012 - val_accuracy: 0.0120\n",
      "Epoch 37/50\n",
      "422/422 [==============================] - 33s 78ms/step - loss: 7.6402 - accuracy: 0.0087 - val_loss: 7.6477 - val_accuracy: 0.0140\n",
      "Epoch 38/50\n",
      "422/422 [==============================] - 33s 78ms/step - loss: 7.7842 - accuracy: 0.0127 - val_loss: 7.6472 - val_accuracy: 0.0160\n",
      "Epoch 39/50\n",
      "422/422 [==============================] - 33s 78ms/step - loss: 7.9896 - accuracy: 0.0122 - val_loss: 7.9392 - val_accuracy: 0.0200\n",
      "Epoch 40/50\n",
      "422/422 [==============================] - 33s 78ms/step - loss: 8.3156 - accuracy: 0.0093 - val_loss: 8.1025 - val_accuracy: 0.0160\n",
      "Epoch 41/50\n",
      "422/422 [==============================] - 33s 78ms/step - loss: 7.6070 - accuracy: 0.0122 - val_loss: 8.2125 - val_accuracy: 0.0120\n",
      "Epoch 42/50\n",
      "422/422 [==============================] - 32s 77ms/step - loss: 7.6238 - accuracy: 0.0133 - val_loss: 8.1124 - val_accuracy: 0.0120\n",
      "Epoch 43/50\n",
      "422/422 [==============================] - 33s 78ms/step - loss: 7.2423 - accuracy: 0.0068 - val_loss: 8.1411 - val_accuracy: 0.0140\n",
      "Epoch 44/50\n",
      "422/422 [==============================] - 33s 78ms/step - loss: 6.8285 - accuracy: 0.0093 - val_loss: 7.8399 - val_accuracy: 0.0100\n",
      "Epoch 45/50\n",
      "422/422 [==============================] - 33s 78ms/step - loss: 7.5062 - accuracy: 0.0107 - val_loss: 8.0776 - val_accuracy: 0.0100\n",
      "Epoch 46/50\n",
      "422/422 [==============================] - 33s 77ms/step - loss: 8.2806 - accuracy: 0.0089 - val_loss: 7.6657 - val_accuracy: 0.0100\n",
      "Epoch 47/50\n",
      "422/422 [==============================] - 33s 77ms/step - loss: 8.1673 - accuracy: 0.0103 - val_loss: 7.9623 - val_accuracy: 0.0100\n",
      "Epoch 48/50\n",
      "422/422 [==============================] - 32s 77ms/step - loss: 6.7202 - accuracy: 0.0095 - val_loss: 7.8760 - val_accuracy: 0.0100\n",
      "Epoch 49/50\n",
      "422/422 [==============================] - 32s 76ms/step - loss: 7.9925 - accuracy: 0.0089 - val_loss: 8.1714 - val_accuracy: 0.0140\n",
      "Epoch 50/50\n",
      "422/422 [==============================] - 32s 77ms/step - loss: 8.4585 - accuracy: 0.0085 - val_loss: 9.1342 - val_accuracy: 0.0080\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "# ... Your existing imports and code ...\n",
    "import tensorflow as tf\n",
    "class BasicBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, filter_num, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=filter_num,\n",
    "                                            kernel_size=(3, 3),\n",
    "                                            strides=stride,\n",
    "                                            padding=\"same\")\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters=filter_num,\n",
    "                                            kernel_size=(3, 3),\n",
    "                                            strides=1,\n",
    "                                            padding=\"same\")\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "        self.residual = tf.keras.layers.Conv2D(filters=filter_num,\n",
    "                                            kernel_size=(1, 1),\n",
    "                                            strides=stride,\n",
    "                                            padding=\"same\")\n",
    "\n",
    "    def call(self, inputs, training=None, **kwargs):\n",
    "        residual = self.residual(inputs)\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x, training=training)\n",
    "        x = tf.keras.layers.Add()([residual, x])\n",
    "        x = tf.nn.relu(x)\n",
    "        return x\n",
    "\n",
    "class PINet18(tf.keras.models.Model):\n",
    "    def __init__(self, block_list, initial_filters=16, num_classes=100, **kwargs):\n",
    "        super(PINet18, self).__init__(**kwargs)\n",
    "        self.num_blocks = len(block_list)\n",
    "        self.block_list = block_list\n",
    "        self.out_filters = initial_filters\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=self.out_filters,\n",
    "                                            kernel_size=(3, 3),\n",
    "                                            strides=1,\n",
    "                                            padding=\"same\")\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.blocks = tf.keras.models.Sequential()\n",
    "\n",
    "        for block_id in range(len(block_list)):\n",
    "            for layer_id in range(block_list[block_id]):\n",
    "                if block_id != 0 and layer_id == 0:\n",
    "                    block = BasicBlock(self.out_filters, stride=2)\n",
    "                else:\n",
    "                    block = BasicBlock(self.out_filters, stride=1)\n",
    "                self.blocks.add(block)\n",
    "            self.out_filters *= 2\n",
    "\n",
    "        self.final_pool = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.fc = tf.keras.layers.Dense(units=num_classes)\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.blocks(x, training=training)\n",
    "        x = self.final_pool(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = PINet18(block_list=[2, 2, 2, 2])  # for PiNet18\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.build(input_shape=(None, 224, 224, 3))\n",
    "# model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=epochs,\n",
    ")\n",
    "\n",
    "# ... Your existing code for testing and evaluation ...\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
