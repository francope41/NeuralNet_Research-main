{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 14:55:53.614789: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-05 14:55:53.704218: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-05 14:55:53.725799: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-05 14:55:54.144070: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64:/usr/local/cuda-11.8/lib64:\n",
      "2024-06-05 14:55:54.144115: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64:/usr/local/cuda-11.8/lib64:\n",
      "2024-06-05 14:55:54.144119: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/avslab/Documents/HalahResearch/tf-gpu-env/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/home/avslab/Documents/HalahResearch/tf-gpu-env/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (50000, 32, 32, 3) (50000, 10)\n",
      "Test data shape: (10000, 32, 32, 3) (10000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 14:55:55.931545: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:55:55.945972: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:55:55.946098: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:55:55.946504: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-05 14:55:55.947451: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:55:55.947553: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:55:55.947630: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:55:55.995193: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:55:55.995337: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:55:55.995420: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:55:55.995488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1154 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:02:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 14:55:56.984217: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8600\n",
      "2024-06-05 14:55:57.073114: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 15s 37ms/step - loss: 2.0149 - accuracy: 0.2299 - val_loss: 1.7700 - val_accuracy: 0.3358\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 1.7686 - accuracy: 0.3255 - val_loss: 1.6723 - val_accuracy: 0.3693\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 1.7427 - accuracy: 0.3538 - val_loss: 1.6327 - val_accuracy: 0.3937\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 1.6577 - accuracy: 0.3765 - val_loss: 1.5873 - val_accuracy: 0.4061\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 1.6151 - accuracy: 0.4001 - val_loss: 1.5617 - val_accuracy: 0.4261\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 1.5611 - accuracy: 0.4226 - val_loss: 1.4669 - val_accuracy: 0.4606\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 1.5168 - accuracy: 0.4443 - val_loss: 1.4388 - val_accuracy: 0.4900\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 1.4580 - accuracy: 0.4707 - val_loss: 1.4490 - val_accuracy: 0.5061\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 1.4220 - accuracy: 0.4853 - val_loss: 1.3301 - val_accuracy: 0.5252\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 1.3741 - accuracy: 0.5048 - val_loss: 1.2991 - val_accuracy: 0.5400\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 1.3581 - accuracy: 0.5136 - val_loss: 1.2710 - val_accuracy: 0.5497\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 1.3195 - accuracy: 0.5286 - val_loss: 1.2443 - val_accuracy: 0.5567\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 1.2870 - accuracy: 0.5390 - val_loss: 1.2259 - val_accuracy: 0.5598\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 1.2569 - accuracy: 0.5516 - val_loss: 1.1880 - val_accuracy: 0.5818\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 1.2302 - accuracy: 0.5636 - val_loss: 1.2574 - val_accuracy: 0.5791\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 1.2706 - accuracy: 0.5551 - val_loss: 1.2199 - val_accuracy: 0.5645\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 1.2272 - accuracy: 0.5645 - val_loss: 1.1849 - val_accuracy: 0.5861\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 1.1890 - accuracy: 0.5793 - val_loss: 1.1167 - val_accuracy: 0.6053\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 15s 37ms/step - loss: 1.1668 - accuracy: 0.5855 - val_loss: 1.1282 - val_accuracy: 0.6150\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 1.1542 - accuracy: 0.5903 - val_loss: 1.0989 - val_accuracy: 0.6114\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 1.1361 - accuracy: 0.5988 - val_loss: 1.1070 - val_accuracy: 0.6283\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 1.1203 - accuracy: 0.6039 - val_loss: 1.0782 - val_accuracy: 0.6176\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 1.0972 - accuracy: 0.6122 - val_loss: 1.1127 - val_accuracy: 0.6098\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 1.1192 - accuracy: 0.6038 - val_loss: 1.1094 - val_accuracy: 0.6083\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 1.0820 - accuracy: 0.6200 - val_loss: 1.0215 - val_accuracy: 0.6403\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 1.0562 - accuracy: 0.6277 - val_loss: 1.0697 - val_accuracy: 0.6400\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 1.0497 - accuracy: 0.6311 - val_loss: 1.0324 - val_accuracy: 0.6370\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 1.0397 - accuracy: 0.6352 - val_loss: 1.0518 - val_accuracy: 0.6372\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 1.0375 - accuracy: 0.6360 - val_loss: 1.0234 - val_accuracy: 0.6427\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 1.0309 - accuracy: 0.6386 - val_loss: 1.0475 - val_accuracy: 0.6281\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 1.0099 - accuracy: 0.6451 - val_loss: 1.0238 - val_accuracy: 0.6447\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 0.9924 - accuracy: 0.6510 - val_loss: 1.0043 - val_accuracy: 0.6613\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 1.0124 - accuracy: 0.6459 - val_loss: 1.0299 - val_accuracy: 0.6528\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 0.9838 - accuracy: 0.6544 - val_loss: 0.9595 - val_accuracy: 0.6687\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 0.9677 - accuracy: 0.6605 - val_loss: 1.0148 - val_accuracy: 0.6525\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 0.9537 - accuracy: 0.6670 - val_loss: 0.9852 - val_accuracy: 0.6628\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.9541 - accuracy: 0.6663 - val_loss: 0.9919 - val_accuracy: 0.6718\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.9440 - accuracy: 0.6715 - val_loss: 1.0648 - val_accuracy: 0.6657\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.9337 - accuracy: 0.6719 - val_loss: 0.9429 - val_accuracy: 0.6744\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 1.1080 - accuracy: 0.6371 - val_loss: 1.1114 - val_accuracy: 0.6136\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 1.0390 - accuracy: 0.6351 - val_loss: 0.9963 - val_accuracy: 0.6652\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.9513 - accuracy: 0.6660 - val_loss: 0.9738 - val_accuracy: 0.6721\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.9240 - accuracy: 0.6768 - val_loss: 0.9338 - val_accuracy: 0.6795\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.9534 - accuracy: 0.6715 - val_loss: 0.9527 - val_accuracy: 0.6776\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 0.9277 - accuracy: 0.6754 - val_loss: 0.9646 - val_accuracy: 0.6844\n",
      "Epoch 46/50\n",
      "139/391 [=========>....................] - ETA: 8s - loss: 0.9002 - accuracy: 0.6859"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=0.00001)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import gc\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input, Add, Dense, Layer, Activation, concatenate, Conv2D, Flatten, MaxPooling2D, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow_addons.layers import WeightNormalization\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Clear the session\n",
    "# K.clear_session()\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "class PrintShapeCallback(Callback):\n",
    "    def __init__(self, model_layer_name):\n",
    "        super(PrintShapeCallback, self).__init__()\n",
    "        self.model_layer_name = model_layer_name\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Get the output of the layer with the specified name\n",
    "        layer_output = self.model.get_layer(self.model_layer_name).output\n",
    "        print(f\"After epoch {epoch+1}, shape of x (from layer {self.model_layer_name}): {layer_output.shape}\")\n",
    "\n",
    "print_shape_callback = PrintShapeCallback(model_layer_name='dense_1')  # Assuming 'dense_1' is the name of the Dense layer after h2(x)\n",
    "\n",
    "class StopAtThresholdCallback(Callback):\n",
    "    def __init__(self, threshold):\n",
    "        super(StopAtThresholdCallback, self).__init__()\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        val_loss = logs.get('val_loss')\n",
    "        if val_loss is not None and val_loss < self.threshold:\n",
    "            print(f\"\\nStopping training as validation loss {val_loss} is below the threshold {self.threshold}\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "# callback = StopAtThresholdCallback(threshold=1e-03)\n",
    "callback = StopAtThresholdCallback(threshold=1.2962e-07)\n",
    "\n",
    "class H1Layer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(H1Layer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.b = self.add_weight(shape=(input_shape[-1],),\n",
    "                                initializer=RandomNormal(mean=0.0,stddev=0.03),\n",
    "                                trainable=True)\n",
    "        super(H1Layer, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        return (self.b * (2 * x))/ (2**(1/2) * np.pi**(1/4))\n",
    "        #return (2 * x) \n",
    "\n",
    "\n",
    "class H2Layer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(H2Layer, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, x, h1):\n",
    "        return (((2*x*(h1)))-2)/(2*(np.pi**(1/4))*np.sqrt(math.factorial(2)))\n",
    "    \n",
    "class H3Layer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(H3Layer, self).__init__(**kwargs)\n",
    "        \n",
    "    def call(self, x, h1, h2):\n",
    "        return (((2 * x * (h2)))-(4 * h1)) / (2**(3/2)*(np.pi**(1/4))*np.sqrt(math.factorial(3)))\n",
    "\n",
    "class H4Layer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(H4Layer, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, x, h2, h3):\n",
    "        return (((2*x*(h3)))-(6*h2)) / (2**2 *(np.pi**(1/4))*np.sqrt(math.factorial(4)))\n",
    "\n",
    "class H5Layer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(H5Layer,self).__init__(**kwargs)\n",
    "\n",
    "    def call(self,x, h3, h4):\n",
    "        return (((2 * x * h4)) - (8 * h3)) / (2**(5/2) * (np.pi**(1/4)) * np.sqrt(math.factorial(5)))\n",
    "\n",
    "#FROM THIS ON NO MODIFICATION ON WEIGHTS\n",
    "class H6Layer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(H6Layer,self).__init__(**kwargs)\n",
    "        \n",
    "    def call(self,x, h4, h5):\n",
    "        return (2*x*(h5))-(10*h4)\n",
    "\n",
    "class TensorDecompositionLayer(Layer):\n",
    "    def __init__(self, rank, **kwargs):\n",
    "        self.rank = rank\n",
    "        super(TensorDecompositionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.factors_a = self.add_weight(shape=(input_shape[-1], self.rank),\n",
    "                                         initializer=RandomNormal(mean=0.0,stddev=0.05),\n",
    "                                         trainable=True)\n",
    "        self.factors_b = self.add_weight(shape=(self.rank, input_shape[-1]),\n",
    "                                        initializer=RandomNormal(mean=0.0,stddev=0.05),\n",
    "                                        trainable=True)\n",
    "        super(TensorDecompositionLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        return tf.matmul(tf.matmul(x, self.factors_a), self.factors_b)\n",
    "\n",
    " \n",
    "class Relu_With_Weight(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Relu_With_Weight, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.b = self.add_weight(shape=(input_shape[-1],),\n",
    "                                initializer=RandomNormal(),\n",
    "                                trainable=True)\n",
    "        super(Relu_With_Weight, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        return K.tanh(x * self.b)\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normalize the images to a 0 to 1 range\n",
    "X_train, X_val = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Convert class vectors to binary class matrices (one-hot encoding)\n",
    "y_train, y_val = to_categorical(y_train, 10), to_categorical(y_test, 10)\n",
    "\n",
    "# Printing the shape of the dataset to confirm\n",
    "print(\"Training data shape:\", x_train.shape, y_train.shape)\n",
    "print(\"Test data shape:\", x_test.shape, y_test.shape)\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "datagen.fit(X_train)\n",
    "\n",
    "def build_model(input_shape, num_classes, filters):\n",
    "    rank = 5\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = input_layer\n",
    "\n",
    "    h1 = H1Layer()\n",
    "    h2 = H2Layer()\n",
    "    h3 = H3Layer()\n",
    "    h4 = H4Layer()\n",
    "    h5 = H5Layer()\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # x = WeightNormalization(Conv2D(filters=filters, kernel_size=(7,7), strides=2, padding='same',kernel_initializer=\"he_normal\"))(x)\n",
    "    x = Conv2D(filters=filters, kernel_size=(7,7), strides=2, padding='same',kernel_initializer=\"he_normal\")(x)\n",
    "\n",
    "    x = x_h1 = h1(x)\n",
    "    # x = WeightNormalization(Conv2D(filters=filters, kernel_size=(5, 5), padding='same',kernel_initializer=\"he_normal\"))(x)\n",
    "    x = Conv2D(filters=filters, kernel_size=(5, 5), padding='same',kernel_initializer=\"he_normal\")(x)\n",
    "    #x = TensorDecompositionLayer(rank)(x)\n",
    "    x = x_h2 = h2(x,x_h1)\n",
    "    # x = WeightNormalization(Conv2D(filters=filters, kernel_size=(3, 3), padding='same',kernel_initializer=\"he_normal\"))(x)\n",
    "    x = Conv2D(filters=filters, kernel_size=(3, 3), padding='same',kernel_initializer=\"he_normal\")(x)\n",
    "    x = x_h3 = h3(x, x_h1, x_h2)\n",
    "    x = Conv2D(filters=filters, kernel_size=(3, 3), padding='same',kernel_initializer=\"he_normal\")(x)\n",
    "    x = x_h4 = h4(x, x_h2, x_h3)\n",
    "    x = Conv2D(filters=filters, kernel_size=(3, 3), padding='same',kernel_initializer=\"he_normal\")(x)\n",
    "    x = x_h5 = h5(x, x_h3, x_h4)\n",
    "    x = Conv2D(filters=filters, kernel_size=(3, 3), padding='same',kernel_initializer=\"he_normal\")(x)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    # x = Dropout(0.5)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu', kernel_initializer=\"he_normal\")(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model\n",
    "\n",
    "input_shape = X_train.shape[1:]\n",
    "num_classes = 10\n",
    "filters = 64\n",
    "\n",
    "model = build_model(input_shape, num_classes, filters)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=0.00001)\n",
    "\n",
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=128),\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=50,\n",
    "                    callbacks=[])\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.evaluate(X_val, y_val)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# Plot the accuracy and loss\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='validation')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 32, 32, 3)   12          ['input_4[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 16, 16, 32)   4736        ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " h1_layer_3 (H1Layer)           (None, 16, 16, 32)   32          ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 16, 16, 32)   25632       ['h1_layer_3[0][0]']             \n",
      "                                                                                                  \n",
      " h2_layer_3 (H2Layer)           (None, 16, 16, 32)   0           ['conv2d_13[0][0]',              \n",
      "                                                                  'h1_layer_3[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 16, 16, 32)   9248        ['h2_layer_3[0][0]']             \n",
      "                                                                                                  \n",
      " h3_layer_3 (H3Layer)           (None, 16, 16, 32)   0           ['conv2d_14[0][0]',              \n",
      "                                                                  'h1_layer_3[0][0]',             \n",
      "                                                                  'h2_layer_3[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 16, 16, 32)   9248        ['h3_layer_3[0][0]']             \n",
      "                                                                                                  \n",
      " h4_layer_3 (H4Layer)           (None, 16, 16, 32)   0           ['conv2d_15[0][0]',              \n",
      "                                                                  'h2_layer_3[0][0]',             \n",
      "                                                                  'h3_layer_3[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 16, 16, 32)   9248        ['h4_layer_3[0][0]']             \n",
      "                                                                                                  \n",
      " h5_layer_3 (H5Layer)           (None, 16, 16, 32)   0           ['conv2d_16[0][0]',              \n",
      "                                                                  'h3_layer_3[0][0]',             \n",
      "                                                                  'h4_layer_3[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 16, 16, 32)   9248        ['h5_layer_3[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling2d_3 (Gl  (None, 32)          0           ['conv2d_17[0][0]']              \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 32)           0           ['global_average_pooling2d_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 256)          8448        ['flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 256)          0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 10)           2570        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 78,422\n",
      "Trainable params: 78,416\n",
      "Non-trainable params: 6\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
